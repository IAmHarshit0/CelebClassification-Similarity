{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9afa007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2c32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = cv.CascadeClassifier('haar_face.xml')\n",
    "eye = cv.CascadeClassifier('haar_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "904f8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_men = '.\\\\dataset\\\\men'\n",
    "path_women = '.\\\\dataset\\\\women'\n",
    "path_cr_men = '.\\\\dataset\\\\cropped\\\\men'\n",
    "path_cr_women = '.\\\\dataset\\\\cropped\\\\women'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a46fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "img_dirs_men = []\n",
    "img_dirs_women = []\n",
    "for entry in os.scandir(path_men):\n",
    "    if entry.is_dir():\n",
    "        img_dirs_men.append(entry.path)\n",
    "for women in os.scandir(path_women):\n",
    "    if women.is_dir():\n",
    "        img_dirs_women.append(women.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75f809b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\dataset\\\\men\\\\Ajay_Devgn',\n",
       " '.\\\\dataset\\\\men\\\\Amitabh_Bachchan',\n",
       " '.\\\\dataset\\\\men\\\\Anil_Kapoor',\n",
       " '.\\\\dataset\\\\men\\\\Salman_Khan',\n",
       " '.\\\\dataset\\\\men\\\\Shah_Rukh_Khan']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dirs_men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b35df235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\dataset\\\\women\\\\Juhi_Chawla',\n",
       " '.\\\\dataset\\\\women\\\\Kajol',\n",
       " '.\\\\dataset\\\\women\\\\Madhuri_Dixit',\n",
       " '.\\\\dataset\\\\women\\\\Shilpa_Shetty_Kundra',\n",
       " '.\\\\dataset\\\\women\\\\Sridevi']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dirs_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fb07d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "if os.path.exists(path_cr_men):\n",
    "    shutil.rmtree(path_cr_men)\n",
    "os.mkdir(path_cr_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c2b6ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(path_cr_women):\n",
    "    shutil.rmtree(path_cr_women)\n",
    "os.mkdir(path_cr_women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47e1a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def crop_img(img_path):\n",
    "#     img = cv.imread(img_path)\n",
    "#     gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "#     faces = face.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "#     for (x,y,w,h) in faces:\n",
    "#         roi_gray = gray[y:y+h, x:x+w]\n",
    "#         roi_color = img[y:y+h, x:x+w]\n",
    "#         eyes = eye.detectMultiScale(roi_gray)\n",
    "#         if len(eyes) >= 2:\n",
    "#             return roi_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fabba355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img_path):\n",
    "    img = cv.imread(img_path)\n",
    "    if img is None:\n",
    "        return []\n",
    "\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = face.detectMultiScale(gray, 1.1, 5)\n",
    "    \n",
    "    cropped_faces = []\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        \n",
    "        eyes = eye.detectMultiScale(roi_gray)\n",
    "        if len(eyes) >= 2:\n",
    "            cropped_faces.append(roi_color)\n",
    "    \n",
    "    return cropped_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "504c4d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cr_img_dirs_men = []\n",
    "# celeb_file_name_men = {}\n",
    "\n",
    "# for img_dir in img_dirs_men:\n",
    "#     count = 1\n",
    "#     celeb_name = img_dir.split('\\\\')[-1]\n",
    "#     # print(celeb_name)\n",
    "#     celeb_file_name_men[celeb_name] = []\n",
    "\n",
    "#     for entry in os.scandir(img_dir):\n",
    "#         roi_color = crop_img(entry.path)\n",
    "\n",
    "#         if roi_color is not None:\n",
    "#             crop_folder = path_cr_men + '\\\\' + celeb_name\n",
    "#             print(crop_folder)\n",
    "            \n",
    "#             if not os.path.exists(crop_folder):\n",
    "#                 os.makedirs(crop_folder)\n",
    "#                 cr_img_dirs_men.append(crop_folder)\n",
    "            \n",
    "#             crop_file = celeb_name + str(count) + '.png'\n",
    "#             crop_file_path = crop_folder + '\\\\' + crop_file\n",
    "\n",
    "#             cv.imwrite(crop_file_path, roi_color)\n",
    "#             celeb_file_name_men[celeb_name].append(crop_file_path)\n",
    "#             count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd2ab919",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_img_dirs_men = []\n",
    "celeb_file_name_men = {}\n",
    "\n",
    "for img_dir in img_dirs_men:\n",
    "    count = 1\n",
    "    celeb_name = img_dir.split('\\\\')[-1]\n",
    "    celeb_file_name_men[celeb_name] = []\n",
    "\n",
    "    for entry in os.scandir(img_dir):\n",
    "        cropped_faces = crop_img(entry.path)  # <-- Now returns list of faces\n",
    "\n",
    "        if not cropped_faces:  # Skip if no valid faces\n",
    "            continue\n",
    "\n",
    "        # Create crop folder if it doesn't exist\n",
    "        crop_folder = os.path.join(path_cr_men, celeb_name)\n",
    "        if not os.path.exists(crop_folder):\n",
    "            os.makedirs(crop_folder)\n",
    "            cr_img_dirs_men.append(crop_folder)\n",
    "\n",
    "        # Save all cropped faces from this image\n",
    "        for face_img in cropped_faces:\n",
    "            crop_file = f\"{celeb_name}_{count}.png\"\n",
    "            crop_file_path = os.path.join(crop_folder, crop_file)\n",
    "\n",
    "            cv.imwrite(crop_file_path, face_img)\n",
    "            celeb_file_name_men[celeb_name].append(crop_file_path)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e78ec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cr_img_dirs_women = []\n",
    "# celeb_file_name_women = {}\n",
    "\n",
    "# for img_dir in img_dirs_women:\n",
    "#     count = 1\n",
    "#     celeb_name = img_dir.split('\\\\')[-1]\n",
    "#     # print(celeb_name)\n",
    "#     celeb_file_name_women[celeb_name] = []\n",
    "\n",
    "#     for entry in os.scandir(img_dir):\n",
    "#         roi_color = crop_img(entry.path)\n",
    "\n",
    "#         if roi_color is not None:\n",
    "#             crop_folder = path_cr_women + '\\\\' + celeb_name\n",
    "#             print(crop_folder)\n",
    "            \n",
    "#             if not os.path.exists(crop_folder):\n",
    "#                 os.makedirs(crop_folder)\n",
    "#                 cr_img_dirs_women.append(crop_folder)\n",
    "            \n",
    "#             crop_file = celeb_name + str(count) + '.png'\n",
    "#             crop_file_path = crop_folder + '\\\\' + crop_file\n",
    "\n",
    "#             cv.imwrite(crop_file_path, roi_color)\n",
    "#             celeb_file_name_women[celeb_name].append(crop_file_path)\n",
    "#             count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0fffa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_img_dirs_women = []\n",
    "celeb_file_name_women = {}\n",
    "\n",
    "for img_dir in img_dirs_women:\n",
    "    count = 1\n",
    "    celeb_name = img_dir.split('\\\\')[-1]\n",
    "    celeb_file_name_women[celeb_name] = []\n",
    "\n",
    "    for entry in os.scandir(img_dir):\n",
    "        cropped_faces = crop_img(entry.path)  # <-- Now returns list of faces\n",
    "\n",
    "        if not cropped_faces:  # Skip if no valid faces\n",
    "            continue\n",
    "\n",
    "        # Create crop folder if it doesn't exist\n",
    "        crop_folder = os.path.join(path_cr_women, celeb_name)\n",
    "        if not os.path.exists(crop_folder):\n",
    "            os.makedirs(crop_folder)\n",
    "            cr_img_dirs_women.append(crop_folder)\n",
    "\n",
    "        # Save all cropped faces from this image\n",
    "        for face_img in cropped_faces:\n",
    "            crop_file = f\"{celeb_name}_{count}.png\"\n",
    "            crop_file_path = os.path.join(crop_folder, crop_file)\n",
    "\n",
    "            cv.imwrite(crop_file_path, face_img)\n",
    "            celeb_file_name_women[celeb_name].append(crop_file_path)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752149b",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f723c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArr = img\n",
    "    imArr = cv.cvtColor(imArr, cv.COLOR_BGR2GRAY)\n",
    "    imArr = np.float32(imArr)\n",
    "    imArr /= 255\n",
    "    \n",
    "    # Coefficients\n",
    "    coeff = pywt.wavedec2(imArr, mode, level=level)\n",
    "    coeff_h = list(coeff)\n",
    "    coeff_h[0] *= 0 \n",
    "    \n",
    "    # Reconsturction \n",
    "    imArr_h = pywt.waverec2(coeff_h, mode)\n",
    "    imArr_h *= 255\n",
    "    imArr_h = np.uint8(imArr_h)\n",
    "\n",
    "    return imArr_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d132ba7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ajay_Devgn': 0,\n",
       " 'Amitabh_Bachchan': 1,\n",
       " 'Anil_Kapoor': 2,\n",
       " 'Salman_Khan': 3,\n",
       " 'Shah_Rukh_Khan': 4}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict_men = {}\n",
    "count = 0\n",
    "for celeb_name in celeb_file_name_men.keys():\n",
    "    class_dict_men[celeb_name] = count\n",
    "    count = count + 1\n",
    "class_dict_men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4d97dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Juhi_Chawla': 0,\n",
       " 'Kajol': 1,\n",
       " 'Madhuri_Dixit': 2,\n",
       " 'Shilpa_Shetty_Kundra': 3,\n",
       " 'Sridevi': 4}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict_women = {}\n",
    "count = 0\n",
    "for celeb_name in celeb_file_name_women.keys():\n",
    "    class_dict_women[celeb_name] = count\n",
    "    count = count + 1\n",
    "class_dict_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33f4517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_men = []\n",
    "y_men = []\n",
    "for celeb_name, training_file in celeb_file_name_men.items():\n",
    "    for train_img in training_file:\n",
    "        img = cv.imread(train_img)\n",
    "\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        scaled_img = cv.resize(img, (32,32))\n",
    "        img_har = w2d(img, 'db1', 5)\n",
    "        scaled_img_har = cv.resize(img_har, (32,32))\n",
    "        combine_img = np.vstack((scaled_img.reshape(32*32*3, 1), scaled_img_har.reshape(32*32, 1)))\n",
    "        x_men.append(combine_img)\n",
    "        y_men.append(class_dict_men[celeb_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2749ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_women = []\n",
    "y_women = []\n",
    "for celeb_name, training_file in celeb_file_name_women.items():\n",
    "    for train_img in training_file:\n",
    "        img = cv.imread(train_img)\n",
    "\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        scaled_img = cv.resize(img, (32,32))\n",
    "        img_har = w2d(img, 'db1', 5)\n",
    "        scaled_img_har = cv.resize(img_har, (32,32))\n",
    "        combine_img = np.vstack((scaled_img.reshape(32*32*3, 1), scaled_img_har.reshape(32*32, 1)))\n",
    "        x_women.append(combine_img)\n",
    "        y_women.append(class_dict_women[celeb_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee295881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_men[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c62d265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30],\n",
       "       [37],\n",
       "       [40],\n",
       "       ...,\n",
       "       [ 1],\n",
       "       [ 5],\n",
       "       [ 6]], shape=(4096, 1), dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_men[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb7679a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 4096)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_men = np.array(x_men).reshape(len(x_men), 4096).astype(float)\n",
    "x_men.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47685a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 4096)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_women = np.array(x_women).reshape(len(x_women), 4096).astype(float)\n",
    "x_women.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "372cacd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30., 37., 40., ...,  1.,  5.,  6.], shape=(4096,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_men[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0253e4",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1018c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0afd13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_women, y_women, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e002a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('Scaler', StandardScaler()), ('PCA', PCA()), ('SVC', SVC(kernel='rbf', C=10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e657032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Scaler&#x27;, StandardScaler()), (&#x27;PCA&#x27;, PCA()),\n",
       "                (&#x27;SVC&#x27;, SVC(C=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;Scaler&#x27;, StandardScaler()), (&#x27;PCA&#x27;, PCA()),\n",
       "                (&#x27;SVC&#x27;, SVC(C=10))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>PCA</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>PCA()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=10)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Scaler', StandardScaler()), ('PCA', PCA()),\n",
       "                ('SVC', SVC(C=10))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12fe6814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4931506849315068"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36fb4aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6bc448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.67      0.53        12\n",
      "           1       0.38      0.33      0.35         9\n",
      "           2       0.37      0.54      0.44        13\n",
      "           3       0.50      0.28      0.36        18\n",
      "           4       0.72      0.62      0.67        21\n",
      "\n",
      "    accuracy                           0.49        73\n",
      "   macro avg       0.48      0.49      0.47        73\n",
      "weighted avg       0.52      0.49      0.49        73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pipe.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64c60e7",
   "metadata": {},
   "source": [
    "# Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d061594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62adf57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'svm': {\n",
    "        'model': SVC(gamma='auto', probability=True),\n",
    "        'params': {\n",
    "            'svc__C' : [1,10,100,1000],\n",
    "            'svc__kernel' : ['rbf', 'linear']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'rf': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'randomforestclassifier__n_estimators' : [1,5,10]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'lr': {\n",
    "        'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C' : [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04da788a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\iamha\\anaconda3\\envs\\tf-jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Score</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.470507</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.296512</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.488901</td>\n",
       "      <td>{'logisticregression__C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Best_Score                                   Best_Params\n",
       "0   svm    0.470507        {'svc__C': 1, 'svc__kernel': 'linear'}\n",
       "1    rf    0.296512  {'randomforestclassifier__n_estimators': 10}\n",
       "2    lr    0.488901                  {'logisticregression__C': 1}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "best_estimator = {}\n",
    "\n",
    "import pandas as pd\n",
    "for algo, mp in param.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf = GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(x_train, y_train)\n",
    "    scores.append({\n",
    "        'Model' : algo,\n",
    "        'Best_Score' : clf.best_score_,\n",
    "        'Best_Params': clf.best_params_\n",
    "    })\n",
    "    best_estimator[algo] = clf.best_estimator_\n",
    "\n",
    "df = pd.DataFrame(scores, columns=['Model', 'Best_Score', 'Best_Params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7b530cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5205479452054794"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator['svm'].score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a9125bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3150684931506849"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator['rf'].score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6a712bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4246575342465753"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator['lr'].score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa88f5f",
   "metadata": {},
   "source": [
    "# Built In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "985599e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Prepare training data\n",
    "faces = []\n",
    "labels = []\n",
    "\n",
    "for idx, (celeb_name, training_files) in enumerate(celeb_file_name_women.items()):\n",
    "    for img_path in training_files:\n",
    "        img = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_resized = cv.resize(img, (100, 100))  # LBPH prefers fixed size\n",
    "        faces.append(img_resized)\n",
    "        labels.append(idx)\n",
    "\n",
    "faces = np.array(faces)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Create and train LBPH recognizer\n",
    "recognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "recognizer.train(faces, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79049bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 3\n",
      "Confidence: 114.51259013556628\n"
     ]
    }
   ],
   "source": [
    "test_img = cv.imread(\"images.jpg\", cv.IMREAD_GRAYSCALE)\n",
    "test_img_resized = cv.resize(test_img, (100, 100))\n",
    "\n",
    "label, confidence = recognizer.predict(test_img_resized)\n",
    "print(\"Predicted Label:\", label)\n",
    "print(\"Confidence:\", confidence)  # lower = better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba3f31",
   "metadata": {},
   "source": [
    "# Face Recognition Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a748dde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (156, 128)\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "class_dict = {name: idx for idx, name in enumerate(celeb_file_name_men.keys())}\n",
    "\n",
    "for celeb_name, image_paths in celeb_file_name_men.items():\n",
    "    for img_path in image_paths:\n",
    "        # Load image\n",
    "        image = face_recognition.load_image_file(img_path)\n",
    "        \n",
    "        # Get face embeddings (128D)\n",
    "        encodings = face_recognition.face_encodings(image)\n",
    "        \n",
    "        if len(encodings) > 0:\n",
    "            X.append(encodings[0])  # 128D vector\n",
    "            y.append(class_dict[celeb_name])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"Feature shape:\", X.shape)  # (num_samples, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "107c16de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (CV): 0.9513333333333334\n",
      "Best Params: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.96875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 0.01, 0.001]  # Only used for RBF\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(SVC(probability=True), param_grid, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Score (CV):\", clf.best_score_)\n",
    "print(\"Best Params:\", clf.best_params_)\n",
    "print(\"Test Accuracy:\", clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7420fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Name: Anil_Kapoor\n",
      "Confidence: 90.63 %\n"
     ]
    }
   ],
   "source": [
    "label_dict = {v: k for k, v in class_dict.items()}\n",
    "\n",
    "test_img_path = \"image.jpg\"\n",
    "image = face_recognition.load_image_file(test_img_path)\n",
    "encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "if len(encodings) > 0:\n",
    "    pred = clf.predict([encodings[0]])[0]\n",
    "    prob = np.max(clf.predict_proba([encodings[0]]))\n",
    "    \n",
    "    print(\"Predicted Name:\", label_dict[pred])\n",
    "    print(\"Confidence:\", round(prob*100, 2), \"%\")\n",
    "else:\n",
    "    print(\"No face detected!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42058cc",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb9232f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf.best_estimator_, 'men_face.pkl')\n",
    "import json \n",
    "with open('men_dict.json', 'w') as f:\n",
    "    json.dump(class_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3fd337ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajay_Devgn: 71.57%\n",
      "Amitabh_Bachchan: 23.32%\n",
      "Anil_Kapoor: 0.7%\n",
      "Salman_Khan: 3.58%\n",
      "Shah_Rukh_Khan: 0.83%\n",
      "\n",
      "Top Prediction: Ajay_Devgn -> 71.57 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_dict = {v: k for k, v in class_dict.items()}\n",
    "\n",
    "test_img_path = \"images.jpg\"\n",
    "image = face_recognition.load_image_file(test_img_path)\n",
    "encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "if len(encodings) > 0:\n",
    "    # Get probabilities for all classes\n",
    "    probs = clf.predict_proba([encodings[0]])[0]\n",
    "\n",
    "    # Show each class with its probability\n",
    "    for class_idx, prob in enumerate(probs):\n",
    "        print(f\"{label_dict[class_idx]}: {round(prob*100, 2)}%\")\n",
    "\n",
    "    # Also show top prediction\n",
    "    pred = np.argmax(probs)\n",
    "    print(\"\\nTop Prediction:\", label_dict[pred], \"->\", round(probs[pred]*100, 2), \"%\")\n",
    "\n",
    "else:\n",
    "    print(\"No face detected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ffbb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-jupyter)",
   "language": "python",
   "name": "tf-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
